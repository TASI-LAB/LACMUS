# LACMUS
This is the source code for our SP'24 paper "LACMUS: Latent Concept Masking for General Robustness Enhancement of DNNs". The autoencoder implementation follows the repository: https://github.com/praeclarumjj3/VQ-VAE-on-MNIST.

Our algorithm provide a novel methodology that enhances DNN robustness by replace concept for training samples without requiring prior knowledge about the adversarial contexts.

## Requirements
Python==3.7

pytorch==2.0.1

torchvision==0.15.2

numpy==1.21.0

## Dataset
- MNIST
- CIFAR
- CELEBA
- IMAGENET

In this repository, we provide a demonstration for MNIST and will release all the code for other datasets.

There is no need to download datasets, and they will automatically be downloaded when running the code.

## Pretrained Model 
The pretrained autoencoder on the 4 datasets will be uploaded via Google Drive Link.

## Usage
### Train Vqvae
If you want to train the vqvae model by yourself for aug sample generation, run

```
python3 VQ-VAE.py --output-folder [NAME_OF_OUTPUT_FOLDER] --data-folder [PATH_TO_MNIST_dataset] --device ['cpu' or 'cuda' ] --hidden-size [SIZE] --k [NUMBER] --batch-size [BATCH_SIZE] --num_epoch [NUMBER_OF_EPOCHS] --lr [LEARNING_RATE] --beta [VALUE] --num-workers [NUMBER_OF_WORKERS]
```

### Train classifier
To train a simply mlp model for mnist dataset, run 

```
python classifier.py
```


### Generate augmentation samples

#### Generate samples with single concept
Run main.py with mode gs_c,

```
! python main.py --mode gs_c --model [VQVAE_WEIGHTS] --classifier-model [CLASSIFIER_WEIGHTS] --concept [CONCEPT_NUMBER]
```


#### Generate samples with all concepts
Run main.py with mode gs,

```
! python main.py --mode gs --model [VQVAE_WEIGHTS] --classifier-model [CLASSIFIER_WEIGHTS]
```

You can merge samples for all concepts by run 

```
python merge_aug_sample.py
```

Samples and information will be save in \aug_sample


### Finetuning model

When you finetune your classifier model, please input your target adversarial sample path in testing_adv_paths.py. Here's an example:
```
testing_adv_paths = [{"name": "fgsm", "images_numpy": "adv_data/mnist_fgsm_0.03125.npy", "labels": "adv_data/mnist_org.npy"},
{"name": "pgd", "images_numpy": "adv_data/mnist_org.npy"},
{"name": "ours", "images_numpy": "aug_sample/aug_sample.npy", "labels": "aug_sample/aug_labels.npy"}]  
```



#### Fintune with the generated simples of a single concept
Run main.py with mode ft_c,

```
python main.py --mode ft_c --model [VQVAE_WEIGHTS] --classifier-model [CLASSIFIER_WEIGHTS] --concept [CONCEPT_NUMBER]
```



#### Fintune with the generated simples of all concepts
Run main.py with mode ft,

```
python main.py --mode ft --model [VQVAE_WEIGHTS] --classifier-model [CLASSIFIER_WEIGHTS]
```



#### Fintune with the generated simples of a single concept, mixed with adversarial sample
Run main.py with mode ft_m_c,

```
python main.py --mode ft --model [VQVAE_WEIGHTS] --classifier-model [CLASSIFIER_WEIGHTS] --adv-path [ADV_SAMPLE_PATH] --adv-label [ADV_LABEL_PATH]
```

Please notice that the adv samples must be generated by training datasets.

### Basic arguments:
```--mode```: the mode of usage, includes gs, gs_c, ft, ft_c, ft_m, rt, rt_c

```--dataset```: the target dataset, includes MNIST, CIFAR10, CELEBA

```--model```: the weight path for the vqvae model

```--classifier-model```: the weight path for the classifier model

```--concept```: the particular concept using while generate sample or finetuning
    
```--org-train-ratio```: default=1.0, the proption of training sample usage while fintuning
    
```--adv-path```: adv sample path for training dataset during finetuning

```--adv-label```: adv sample label path for training dataset during finetuning


## MNIST Demo
Check mnist_demo.ipynb to see the quick demo for mnist dataset.
